{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf64ae5",
   "metadata": {},
   "source": [
    "# Pyspark fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48be0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827c2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97aeb40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "| 24|    Emily|female|   Jones| 456754675|\n",
      "+---+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the json file people that is placed in same path as this notebook. Else specify full path\n",
    "df = spark.read.json('people.json')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c7005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printSchema is used to print the schema of the dataframe. It displays the datatype and if the field is nullable. \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531dc1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'firstName', 'gender', 'lastName', 'number']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769e3436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, age: string, firstName: string, gender: string, lastName: string, number: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  describing the dataframe structure. describe() displays the datatype and field name\n",
    "# as seen age is string here\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33eb2406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+------+--------+--------------------+\n",
      "|summary| age|firstName|gender|lastName|              number|\n",
      "+-------+----+---------+------+--------+--------------------+\n",
      "|  count|   3|        3|     3|       3|                   3|\n",
      "|   mean|28.0|     null|  null|    null| 4.494868541333333E9|\n",
      "| stddev| 4.0|     null|  null|    null|3.5954963302739053E9|\n",
      "|    min|  24|    Emily|female| Jackson|           456754675|\n",
      "|    max|  32|      Joe|  male|   Smith|          7349282382|\n",
      "+-------+----+---------+------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe() along with show() displays count, mean, stddev, min and max details. \n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4914f",
   "metadata": {},
   "source": [
    "### Creating user defined schema with datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283d938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required methods from the package pyspark.sql.types\n",
    "from pyspark.sql.types import (StructType, StructField, \n",
    "                               IntegerType, StringType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a07a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a schema with the columns age, firstName, gender, lastName and number with required datatypes. \n",
    "# as seen age is defined as Integer now. \n",
    "data_schema = [StructField (('age'), IntegerType(), True ),\n",
    "               StructField (('firstName'), StringType(), True ),\n",
    "               StructField (('gender'), StringType(), True ),\n",
    "               StructField (('lastName'), StringType(), True ),\n",
    "               StructField (('number'), StringType(), True )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6644a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the schema is required, create the Structure Type and assign the data_schema that is created. \n",
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab1488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the json file with the user defined file structure. \n",
    "df = spark.read.json('people.json', schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed91a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schema with userdefined structure. \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e96f1ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "| 24|    Emily|female|   Jones| 456754675|\n",
      "+---+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242cdbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'age'>\n",
      "<class 'pyspark.sql.column.Column'>\n"
     ]
    }
   ],
   "source": [
    "# df['age'] displays the Column but not exact data. \n",
    "print(df['age'])\n",
    "\n",
    "# When the type() is displayed, we can see its column.Column\n",
    "print(type(df['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee8a422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 28|\n",
      "| 32|\n",
      "| 24|\n",
      "+---+\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# To display the data of any column, we need to use .select() function like SQL. \n",
    "df.select('age').show()\n",
    "\n",
    "# type() would display its dataframe.Dataframe\n",
    "print(type(df.select('age')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3804c8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|gender|\n",
      "+---+------+\n",
      "| 28|  male|\n",
      "| 32|  male|\n",
      "| 24|female|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to display multiple columns, specify the column names within select()\n",
    "df.select('age','gender').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10f8d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(age=28, firstName='Joe', gender='male', lastName='Jackson', number='7349282382'), Row(age=32, firstName='James', gender='male', lastName='Smith', number='5678568567')]\n",
      "------------------------------------\n",
      "Row(age=28, firstName='Joe', gender='male', lastName='Jackson', number='7349282382')\n",
      "------------------------------------\n",
      "<class 'pyspark.sql.types.Row'>\n"
     ]
    }
   ],
   "source": [
    "# head() is used to Row data as RowData. \n",
    "# head(2) displays 2 records as list elements. \n",
    "# to select the 1st element from the list here, need to use the [0] and to select 2nd element, use [1], just like accessing list elements\n",
    "\n",
    "print(df.head(2))\n",
    "print('------------------------------------')\n",
    "print(df.head(2)[0])\n",
    "print('------------------------------------')\n",
    "print(type((df.head(2)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6bcb06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "+---+---------+------+--------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to display first two entries in the dataframe use show(2)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f122e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+------+\n",
      "|age|firstName|gender|lastName|    number|newAge|\n",
      "+---+---------+------+--------+----------+------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|    56|\n",
      "| 32|    James|  male|   Smith|5678568567|    64|\n",
      "| 24|    Emily|female|   Jones| 456754675|    48|\n",
      "+---+---------+------+--------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumn adds new column to dataframe. We are adding 'newAge' here with value as twice of 'age'\n",
    "# !!!!!! Remember its temporary data unless it is assigned to some other dataFrame. !!!!!\n",
    "df.withColumn('newAge',df['age']*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2830d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "| 24|    Emily|female|   Jones| 456754675|\n",
      "+---+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As seen below, the new column newAge is not really added to dataframe df. \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37a6fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+------+\n",
      "|age|firstName|gender|lastName|    number|newAge|\n",
      "+---+---------+------+--------+----------+------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|    56|\n",
      "| 32|    James|  male|   Smith|5678568567|    64|\n",
      "| 24|    Emily|female|   Jones| 456754675|    48|\n",
      "+---+---------+------+--------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assigning the df with new column to df_new. \n",
    "df_new = df.withColumn('newAge',df['age']*2).show()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2957ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------+----------+\n",
      "|new_age|firstName|gender|lastName|    number|\n",
      "+-------+---------+------+--------+----------+\n",
      "|     28|      Joe|  male| Jackson|7349282382|\n",
      "|     32|    James|  male|   Smith|5678568567|\n",
      "|     24|    Emily|female|   Jones| 456754675|\n",
      "+-------+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumnRenamed is used to rename the existing column. \n",
    "# !!!!!! Remember its temporary data unless it is assigned to some other dataFrame. !!!!!\n",
    "df.withColumnRenamed('age','new_age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11298f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "| 24|    Emily|female|   Jones| 456754675|\n",
      "+---+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As seen below, the new column newAge is not really added to dataframe df.\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d0687ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------+----------+\n",
      "|new_age|firstName|gender|lastName|    number|\n",
      "+-------+---------+------+--------+----------+\n",
      "|     28|      Joe|  male| Jackson|7349282382|\n",
      "|     32|    James|  male|   Smith|5678568567|\n",
      "|     24|    Emily|female|   Jones| 456754675|\n",
      "+-------+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assigning the df with new column to df_new. \n",
    "df_new1 = df.withColumnRenamed('age','new_age').show()\n",
    "df_new1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84c675",
   "metadata": {},
   "source": [
    "### Creating the Temporary View with the dataframe to access like the DB2/SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d71ab94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying the dataframe data to Temporary View names 'people'\n",
    "df.createOrReplaceTempView('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a6580fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "| 24|    Emily|female|   Jones| 456754675|\n",
      "+---+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the data from 'people' can be queried now like SQL Queries using SELECT as seen below\n",
    "results = spark.sql(\"select * from people\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c05e9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "+---+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query can contain the conditions as well just like regular SQL queries using WHERE clause\n",
    "results = spark.sql(\"select * from people where age > 25\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a0810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
